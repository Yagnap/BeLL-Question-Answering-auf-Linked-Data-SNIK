%*****************************************
\chapter{Diskussion und Ausblick}\label{ch:discussion}
%*****************************************

\section{Benchmark}

Der Benchmark wurde erstellt, indem Fragen aus \citet{bb} genommen wurden und wegen ihrer theoretischen Beantwortbarkeit klassifiziert wurden.
Die Eignung dieser Fragen für ein System, das anhand der gegebenen Frage und den in ihr enthaltenen Wörter herausfinden soll, was die Antwort auf sie ist, ist manchmal fraglich.
Oft gibt es Fragen wie \texttt{9.3.4.2/1}, \enquote{Which organizational units are involved in information management?}, wo Ressourcen nicht mit ihrem Namen genannt werden.
Hier wird das Prädikat \aurl{meta}{functionComponent} verwendet, obwohl \aurl{meta}{isInvolvedIn} deutlich naheliegender ist.
Dies lässt auf eine eventuelle Untauglichkeit der Fragen für die Ontologie schließen, oder auf eine manchmal nicht optimal modellierte Datenbasis.

Es ist aber trotzdem gelungen, die gegebenen Fragen, welche auch teilweise beantwortet werden können, einen Benchmark zu erstellen.
Dieser besteht aus Fragen, welche auf in \citet{bb} vorhandenes Wissen zurückgreifen und dieses festigen soll.
Dies ist eigentlich perfekt für die Nutzung mit \ac{snik}, nur die Formulierung ist manchmal nicht optimal.
Es lässt sich allerdings auch sagen, dass die Fragen für \acl{qa} von simplen Fragen vergleichsweise definitiv höchst komplex waren.
Die einfachen Fragen waren recht schnell generierbar und haben die große Datenmenge \ac{snik}s gut genutzt,
auch wenn durch die Anzahl der Tripel in der Teilontologie \texttt{bb}, 2056, erst mehr Fragen erhofft waren.
Dies war allerdings aufgrund von fehlenden Labels oder Subjekten, welche mit vielen Objekten über das gleiche Prädikat verbunden waren und somit die gleiche Frage erzeugten,
was über das Schlüsselwort \texttt{DISTINCT} gekürzt wurde.

Es könnte darüber nachgedacht werden, die automatisch generierten Fragen komplexer zu machen, dies ist aber nicht unbedingt erforderlich.
Es konnten viele Fragen automatisch generiert werden, was viel mehr Trainingsfragen bedeutet hat, was auch dem fine-tuning hilft.
Gerade die Fragen mit verschiedenen Intentionen sind hilfreich.
Allerdings würde damit die Funktion der einfachen Fragen als Basiswerte negiert die Rolle der Lehrbuchfragen als komplexere, der Realität näher liegende Fragen behindert. 

In Zukunft sollten noch mehr schwierigere Fragen erstellt werden.
Denkbar wäre vor allem, Studierende der Medizininformatik nach Fragen, die sie fragen würden, zu fragen.
Für die Realisierung wäre vermutlich die Nutzung ein digitaler Fragebogen möglich, über den die Studierenden benachrichtigt würden und in den sie Fragen eintragen könnten,
eine analoge Lösung wäre auch denkbar.
Problematisch hieran wäre, sofern genügend Fragen gefunden würden, der große Arbeitsaufwand für die manuelle Erstellung der \ac{sparql}-Abfragen, als auch die Möglichkeit der Ontologie, diese zu beantworten.
Die Fragen würden von Menschen erstellt, die wirklich eine Antwort auf die Frage erhalten wollen, und würden sehr individuell und vielfältig gestaltet sein.
Dies birgt aber wieder das Problem, dass sie von \ac{qa}-Systemen aufgrund ihrer Art, Komplexität oder Formulierung nicht beantwortet werden können.
Es ist aber trotzdem ein Ansatz, der betrachtet werden sollte.

\section{Systeme}

Die Erwartung war, dass das Feld mittlerweile reif genug für Systeme ist, die das einfache und präzise Nutzen von semantischem \acl{qa} ermöglichen.
Es war aber sehr schwer, Systeme mit ausreichender Dokumentation und bereitgestelltem Programm zu finden, die noch dazu mit eigenen Daten und vielleicht sogar über mehrere Ontologien verwendbar waren.
Die meisten davon funktionieren jedoch nicht.

Es muss allerdings auch gesagt werden, dass \ac{snik} nicht besonders für semantisches \acl{qa} geeignet ist.
Dieses geht meist, wie in \cref{sub:qasysteme} gesehen, nach der Methode vor, dass die Prädikate der \ac{sparql}-Abfrage den Prädikaten des Satzes entsprechen sollen.
Da \ac{snik} auf verhältnismäßig wenigen Prädikaten beruht, deren Label noch dazu oft wenig in einem natürlichen Satz verwendet würden, ist es meist unpraktikabel, solche zu verwenden.
Ein Ansatz für die Lösung dieses Problems ist die \ac{boa} Pattern Library \citep{boapatternlibrary}, welche aus freiem Text \ac{rdf}-Prädikate extrahieren soll, oder die manuelle Erweiterung durch alternative Labels.

An Ausnahmen wie \aurl{meta}{isResponsibleForFunction} sieht man, dass diese deutlich besser funktionieren, da sie etwa in der Frage \enquote{What is the CIO responsible for?} vorhanden sind.
Prädikate wie \aurl{meta}{entityTypeComponent} mit dem Label \enquote{entity type component} haben es dort schwerer, da sie auf das Metamodell \ac{snik}s zurückgreifen
und nicht den normalen Sprachgebrauch wiederspiegeln.
Hilfreich dafür sind definitiv die Property Mappings von QAnswer, aber diese haben auch nur eine auf die eingegebenen Lexikalisierungen begrenzte Wirkungsweite.

Problematisch an QAnswer ist, dass die Abfragen, denen der höchste Confidence-Wert zugeordnet wurde, manchmal nicht als erstes ausgeführt werden.
Dies ist selbst der Fall, wenn der Wert unter 50\% liegt.
Unter 50\% Confidence sieht QAnswer eine Antwort als falsch an und gibt sie nicht aus \citep{qanswer}.
Des Weiteren soll die Antwort mit dem höchsten Confidence-Wert ausgegeben werden, wobei es hierbei noch zu einigen Verrechnungen anderer Faktoren kommen kann \citep{qanswerpatentapplication}.
So führt QAnswer beispielsweise bei der Frage \enquote{What is used by Medical and Nursing Care planning?},
einer automatisch generierten Frage, die \ac{sparql}-Abfrage mit den drei Prädikaten \emph{function component}, \emph{is involved in}, \emph{is responsible for}, \emph{supports} aus.
Der Confidence-Wert für diese Antwort ist 53\%, der Confidence-Wert für die richtige Antwort 93\%; diese wird aber nicht aufgeführt.
Die richtige Antwort enthält nur das Property \emph{uses} und hat \emph{Medical and Nursing Care planning} an der ersten Stelle des Tripels, ist also auch bedeutend einfacher.

Noch stärker sichtlich wird dieses Problem, wenn man einen Rechtschreibfehler einbaut und \enquote{Medicl} statt \enquote {Medical} schreibt.
Hier wird eine andere falsche Antwort ausgeführt und gezeigt, diese hat nur einen Confidence-Wert von 35\%, die richtige, die hinter einem Menu versteckt ist, wieder einen von 93\%.

Es ist nicht, wie anfangs gewollt, gelungen, ein semantisches \ac{qa}-System über alle drei Teilontologien zuverlässig verwendbar zu machen,
jedoch ist es gelungen, ein \ac{qa}-System über eine Teilontologie zumindest theoretisch verwendbar zu machen, die Erfolgsrate ist beim untrainierten System bei den gegebenen Umständen mit einem F-Maß von 0.24 erstaunlich, jedoch war das Training enttäuschend.
Es bleibt abzuwarten, was das Training mit dem großen, automatisch generierten Benchmark verursacht.\todo{update}
Vermutlich waren die 18 Fragen, die zum Training eingesetzt wurden, deutlich zu wenige, um irgendeine Verallgemeinerung möglich zu machen und das System auf die Ontologie einzustellen.\todo{update}

Für die Verwendung der Teilontologien zusammen fehlt nicht nur ein System, dass diese Aufgabe bewältigt, sondern vor allem auch schlicht die Trainingsfragen.
Bereits die aus dem blauen Buch waren nur teilweise geeignet, für das Training für aller Teilontologien müsste man vermutlich Nutzerfragen von Studierenden sammeln.
Noch dazu kommt das Problem der Ambiguität verschiedener Begriffe, welches mit verschiedenen Teilontologien eingeführt wird.
Natürlich können die Ressourcen, die mit \aurl{skos}{closeMatch} oder \aurl{skos}{exactMatch} verbunden sind, als ähnlich, vielleicht sogar gleich definiert werden.
Aber es gibt ja auch Ressourcen, die nur über \aurl{skos}{broadMatch} oder gar nicht verbunden sind und trotzdem fast gleich heißen.
Solche Ambiguitäten gilt es aufzulösen, das ist ein weiterer Grund, warum hier nur eine Teilontologie abgefragt wurde.

In Zukunft sollte das System definitiv, wie schon geplant, auch am automatisch definierten Benchmark evaluiert werden und der Effekt der Anzahl und des Typs der Fragen ausgewertet werden.\todo{update}
Auch denkbar wäre das Erstellen eines eigenen, auf \ac{snik} spezialisierten, \ac{qa}-Systems, was aber aufgrund der hohen Komplexität unpraktisch erscheint.\todo{update}

Für eine Nutzung des Systems durch Studenten sind die Ergebnisse momentan aber nicht ausreichend.
Infrage kommend wäre höchstens das untrainierte System, welches eine halbwegs akkurate Beantwortung von Fragen, besonders leichteren, ermöglicht.\todo{update}
